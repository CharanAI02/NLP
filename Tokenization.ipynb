{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\chara\\anaconda3\\envs\\ragenv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\chara\\anaconda3\\envs\\ragenv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\chara\\anaconda3\\envs\\ragenv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chara\\anaconda3\\envs\\ragenv\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chara\\anaconda3\\envs\\ragenv\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\chara\\anaconda3\\envs\\ragenv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (3.9.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.5\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "     -------------- ------------------------- 0.5/1.4 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 1.3/1.4 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.4/1.4 MB 2.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: click in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk==3.5) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk==3.5) (1.4.2)\n",
      "Requirement already satisfied: regex in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk==3.5) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from nltk==3.5) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\chara\\anaconda3\\envs\\nlpenv\\lib\\site-packages (from click->nltk==3.5) (0.4.6)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434689 sha256=5a46bfbf4f35e7b8ce841870aba86b27a3fe0f03bfd8abc3b57aebec820c649f\n",
      "  Stored in directory: c:\\users\\chara\\appdata\\local\\pip\\cache\\wheels\\35\\ab\\82\\f9667f6f884d272670a15382599a9c753a1dfdc83f7412e37d\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.9.1\n",
      "    Uninstalling nltk-3.9.1:\n",
      "      Successfully uninstalled nltk-3.9.1\n",
      "Successfully installed nltk-3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk==3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\chara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Helo i'm charan, currently i am learning NLP. On the first basis i'm learning Tokenization\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus= '''Helo i'm charan, currently i am learning NLP. On the first basis i'm learning Tokenization'''\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Helo i'm charan, currently i am learning NLP.\", \"On the first basis i'm learning Tokenization\"]\n"
     ]
    }
   ],
   "source": [
    "documents=sent_tokenize(corpus)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Helo',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'charan',\n",
       " ',',\n",
       " 'currently',\n",
       " 'i',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'On',\n",
       " 'the',\n",
       " 'first',\n",
       " 'basis',\n",
       " 'i',\n",
       " \"'m\",\n",
       " 'learning',\n",
       " 'Tokenization']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Helo',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'charan',\n",
       " ',',\n",
       " 'currently',\n",
       " 'i',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'On',\n",
       " 'the',\n",
       " 'first',\n",
       " 'basis',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'learning',\n",
       " 'Tokenization']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treetokenizer=TreebankWordDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', ' ', 'e', ' ', 'l', ' ', 'o', ' ', ' ', ' ', 'i', \"'\", ' ', 'm', ' ', ' ', ' ', 'c', ' ', 'h', ' ', 'a', ' ', 'r', ' ', 'a', ' ', 'n', ',', ' ', ' ', ' ', 'c', ' ', 'u', ' ', 'r', ' ', 'r', ' ', 'e', ' ', 'n', ' ', 't', ' ', 'l', ' ', 'y', ' ', ' ', ' ', 'i', ' ', ' ', ' ', 'a', ' ', 'm', ' ', ' ', ' ', 'l', ' ', 'e', ' ', 'a', ' ', 'r', ' ', 'n', ' ', 'i', ' ', 'n', ' ', 'g', ' ', ' ', ' ', 'N', ' ', 'L', ' ', 'P', ' ', '.', ' ', ' ', ' ', 'O', ' ', 'n', ' ', ' ', ' ', 't', ' ', 'h', ' ', 'e', ' ', ' ', ' ', 'f', ' ', 'i', ' ', 'r', ' ', 's', ' ', 't', ' ', ' ', ' ', 'b', ' ', 'a', ' ', 's', ' ', 'i', ' ', 's', ' ', ' ', ' ', 'i', \"'\", ' ', 'm', ' ', ' ', ' ', 'l', ' ', 'e', ' ', 'a', ' ', 'r', ' ', 'n', ' ', 'i', ' ', 'n', ' ', 'g', ' ', ' ', ' ', 'T', ' ', 'o', ' ', 'k', ' ', 'e', ' ', 'n', ' ', 'i', ' ', 'z', ' ', 'a', ' ', 't', ' ', 'i', ' ', 'o', ' ', 'n']\n"
     ]
    }
   ],
   "source": [
    "print(list(Treetokenizer.tokenize(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
